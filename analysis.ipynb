{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H24HcPVw68fM",
        "outputId": "365d36d8-97ce-4158-a739-908a83d499df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.activations import softplus\n",
        "import joblib\n",
        "\n",
        
        "df = pd.read_csv(\"/content/drive/MyDrive/Metro_Interstate_Traffic_Volume.csv\")\n",
        "df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "df.set_index('date_time', inplace=True)\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        
        "le_holiday = LabelEncoder()\n",
        "df['holiday'] = df['holiday'].astype(str) # Convert to string before encoding\n",
        "df['holiday'] = le_holiday.fit_transform(df['holiday'])\n",
        "\n",
        "le_weather = LabelEncoder()\n",
        "df['weather_main'] = le_weather.fit_transform(df['weather_main'])\n",
        "df['weather_description'] = le_weather.fit_transform(df['weather_description'])\n",
        "\n",
        "Runtime Features\n",
        "df['hour'] = df.index.hour\n",
        "df['day_of_week'] = df.index.dayofweek\n",
        "df['month'] = df.index.month\n",
        "df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
        "df['is_rush_hour'] = df['hour'].isin([7,8,16,17]).astype(int)\n",
        "\n",
        "Cyclic encoding\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
        "\n",
        "Lag features\n",
        "df['traffic_lag1'] = df['traffic_volume'].shift(1).fillna(method='bfill')\n",
        "df['traffic_lag2'] = df['traffic_volume'].shift(2).fillna(method='bfill')\n",
        "\n",
        "Rolling averages\n",
        "df['traffic_rolling3'] = df['traffic_volume'].rolling(3).mean().fillna(method='bfill')\n",
        "df['rain_3h'] = df['rain_1h'].rolling(3).mean().fillna(0)\n",
        "df['snow_3h'] = df['snow_1h'].rolling(3).mean().fillna(0)\n",
        "df['temp_3h'] = df['temp'].rolling(3).mean().fillna(df['temp'])\n",
        "\n",
        "Features and target\n",
        "features = [\n",
        "    'holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all',\n",
        "    'weather_main', 'weather_description',\n",
        "    'hour', 'day_of_week', 'month', 'is_weekend', 'is_rush_hour',\n",
        "    'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "    'traffic_lag1', 'traffic_lag2',\n",
        "    'traffic_rolling3', 'rain_3h', 'snow_3h', 'temp_3h'\n",
        "]\n",
        "target = ['traffic_volume']\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "Normalization\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "Sequences\n",
        "SEQ_LENGTH = 10\n",
        "def create_sequences(X, y, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X)-seq_length):\n",
        "        X_seq.append(X[i:i+seq_length])\n",
        "        y_seq.append(y[i+seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LENGTH)\n",
        "\n",
        "Split train/test\n",
        "train_size = int(len(X_seq)*0.8)\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "\n",
        "LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(SEQ_LENGTH, X_seq.shape[2])))\n",
        "model.add(Dense(1, activation=softplus))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "Train\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1)\n",
        "model.save(\"models/traffic_lstm_model.h5\")\n",
        "\n",
        "Save scalers\n",
        "joblib.dump(scaler_X, \"models/scaler_X.pkl\")\n",
        "joblib.dump(scaler_y, \"models/scaler_y.pkl\")\n",
        "\n",
        "Predict\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_pred = np.maximum(0, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls3MkWpN37jT",
        "outputId": "418d5aaa-b876-4979-ffb3-f2390583eb8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-515487597.py:45: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['traffic_lag1'] = df['traffic_volume'].shift(1).fillna(method='bfill')\n",
            "/tmp/ipython-input-515487597.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['traffic_lag2'] = df['traffic_volume'].shift(2).fillna(method='bfill')\n",
            "/tmp/ipython-input-515487597.py:49: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['traffic_rolling3'] = df['traffic_volume'].rolling(3).mean().fillna(method='bfill')\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0260 - val_loss: 0.0077\n",
            "Epoch 2/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0089 - val_loss: 0.0074\n",
            "Epoch 3/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0069 - val_loss: 0.0037\n",
            "Epoch 4/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0038\n",
            "Epoch 5/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0035\n",
            "Epoch 6/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 0.0055 - val_loss: 0.0033\n",
            "Epoch 7/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0032\n",
            "Epoch 8/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0035\n",
            "Epoch 9/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0032\n",
            "Epoch 11/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0029\n",
            "Epoch 12/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0030\n",
            "Epoch 13/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0029\n",
            "Epoch 14/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0030\n",
            "Epoch 15/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0032\n",
            "Epoch 16/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0032\n",
            "Epoch 17/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0026\n",
            "Epoch 18/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0030\n",
            "Epoch 19/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0028\n",
            "Epoch 20/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0025\n",
            "Epoch 21/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0026\n",
            "Epoch 22/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0027\n",
            "Epoch 23/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0030\n",
            "Epoch 24/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0028\n",
            "Epoch 25/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0025\n",
            "Epoch 26/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0026\n",
            "Epoch 27/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0025\n",
            "Epoch 28/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 29/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0028\n",
            "Epoch 30/30\n",
            "\u001b[1m1085/1085\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        }
      ]
    }
  ]
}
